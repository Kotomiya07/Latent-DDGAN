{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c304b6-871e-4f8b-8e50-4cbf1ab46c70",
   "metadata": {},
   "source": [
    "\n",
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9589260c-50a2-4050-b385-4aa9acb9eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a87a4-3315-430c-8db0-69dcbb9b297b",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6ef80e-c53e-4687-ab90-c0422a49da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891bc25-8b42-4d7e-ab93-be83c4585ff0",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c25d872-bb86-4525-ba72-30951f955396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "args = [\n",
    "    \"--dataset\", \"coco\", \"--image_size\", \"256\",\n",
    "    \"--exp\", \"g1222_128_2block_d4_attn16_nz50_64\", \"--num_channels\", \"3\",\n",
    "    \"--num_channels_dae\", \"128\", \"--ch_mult\", \"1\", \"2\", \"2\", \"2\", \n",
    "    \"--num_timesteps\", \"2\", \"--num_res_blocks\", \"2\", \n",
    "    \"--batch_size\", \"8\", \"--num_epoch\", \"200\", \n",
    "    \"--ngf\", \"64\", \"--embedding_type\", \"positional\", \n",
    "    \"--use_ema\", \"--ema_decay\", \"0.999\",\n",
    "    \"--r1_gamma\", \"2.\", \"--nz\", \"100\",\n",
    "    \"--z_emb_dim\", \"256\", \"--lr_d\", \"1.0e-4\",\n",
    "    \"--lr_g\", \"2e-4\", \"--lazy_reg\", \"10\",\n",
    "    \"--save_content\", \"--datadir\", \"data/coco\", \n",
    "    \"--master_port\", \"6084\", \"--num_process_per_node\", \"0\",\n",
    "    \"--current_resolution\", \"64\", \"--attn_resolution\", \"16\",\n",
    "    \"--num_disc_layers\", \"4\", \"--rec_loss\", \n",
    "    \"--save_content_every\", \"1\", \"--AutoEncoder_config\", \"./autoencoder/config/COCO_config.yaml\", \n",
    "    \"--AutoEncoder_ckpt\", \"./autoencoder/weight/kl-f4.ckpt\", \"--scale_factor\", \"6.0\", \n",
    "    \"--no_lr_decay\", \"--sigmoid_learning\"\n",
    "]\n",
    "\n",
    "args = get_args(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3b19e-5201-406c-8b46-e7bdc4887b7d",
   "metadata": {},
   "source": [
    "## wandb setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66391d0e-24a1-4371-b5f8-06632cc40445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkotomiya07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/box/MyFolder/project/Latent-DDGAN/wandb/run-20240724_134428-mxlm8zfh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kotomiya07/LDGAN/runs/mxlm8zfh' target=\"_blank\">wild-galaxy-55</a></strong> to <a href='https://wandb.ai/kotomiya07/LDGAN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kotomiya07/LDGAN' target=\"_blank\">https://wandb.ai/kotomiya07/LDGAN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kotomiya07/LDGAN/runs/mxlm8zfh' target=\"_blank\">https://wandb.ai/kotomiya07/LDGAN/runs/mxlm8zfh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kotomiya07/LDGAN/runs/mxlm8zfh?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4147c9d420>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "            project=\"LDGAN\",\n",
    "            config={\n",
    "                \"dataset\": args.dataset,\n",
    "                \"image_size\": args.image_size,\n",
    "                \"channels\": args.num_channels,\n",
    "                \"timesteps\": args.num_timesteps,\n",
    "                \"nz\": args.nz,\n",
    "                \"epochs\": args.num_epoch,\n",
    "                \"ngf\": args.ngf,\n",
    "                \"lr_g\": args.lr_g,\n",
    "                \"lr_d\": args.lr_d,\n",
    "                \"batch_size\": args.batch_size,\n",
    "                \"r1_gamma\": args.r1_gamma,\n",
    "                \"lazy_reg\": args.lazy_reg,\n",
    "                \"use_ema\": args.use_ema,\n",
    "                \"ema_decay\": args.ema_decay,\n",
    "                \"no_lr_decay\": args.no_lr_decay,\n",
    "                \"use_pytorch_wavelet\": args.use_pytorch_wavelet,\n",
    "                \"rec_loss\": args.rec_loss,\n",
    "                \"net_type\": args.net_type,\n",
    "                \"num_disc_layers\": args.num_disc_layers,\n",
    "                \"no_use_fbn\": args.no_use_fbn,\n",
    "                \"no_use_freq\": args.no_use_freq,\n",
    "                \"no_use_residual\": args.no_use_residual,\n",
    "                \"scale_factor\": args.scale_factor,\n",
    "                \"AutoEncoder_config\": args.AutoEncoder_config,\n",
    "                \"AutoEncoder_ckpt\": args.AutoEncoder_ckpt,\n",
    "                \"sigmoid_learning\": args.sigmoid_learning,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6c9d4-8d3f-4fef-aa53-8248caebf840",
   "metadata": {},
   "source": [
    "## train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce020e4-4a06-4f99-b867-125d37ee0539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.74s)\n",
      "creating index...\n",
      "index created!\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 13:44:34.303120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-24 13:44:34.322528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-24 13:44:34.322554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-24 13:44:34.323286: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-24 13:44:34.327097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 13:44:35.040107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "gpu = 0\n",
    "\n",
    "from EMA import EMA\n",
    "from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "torch.manual_seed(args.seed + rank)\n",
    "torch.cuda.manual_seed(args.seed + rank)\n",
    "torch.cuda.manual_seed_all(args.seed + rank)\n",
    "device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "nz = args.nz  # latent dimension\n",
    "\n",
    "dataset = create_dataset(args)\n",
    "#train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "#                                                                num_replicas=args.world_size,\n",
    "#                                                                rank=rank)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=args.num_workers,\n",
    "                                          pin_memory=True,\n",
    "                                          #sampler=train_sampler,\n",
    "                                          drop_last=True)\n",
    "args.ori_image_size = args.image_size\n",
    "args.image_size = args.current_resolution\n",
    "G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "gen_net = G_NET_ZOO[args.net_type]\n",
    "disc_net = [Discriminator_small, Discriminator_large]\n",
    "print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "netG = gen_net(args).to(device)\n",
    "\n",
    "if args.dataset in ['cifar10', 'stl10']:\n",
    "    netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                       t_emb_dim=args.t_emb_dim,\n",
    "                       act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "else:\n",
    "    netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                       t_emb_dim=args.t_emb_dim,\n",
    "                       act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "#broadcast_params(netG.parameters())\n",
    "#broadcast_params(netD.parameters())\n",
    "\n",
    "optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    ")), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    ")), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "if args.use_ema:\n",
    "    optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "\n",
    "schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "# ddp\n",
    "#netG = nn.parallel.DistributedDataParallel(\n",
    "#    netG, device_ids=[gpu], find_unused_parameters=True)\n",
    "#netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "\"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "# Wavelet Pooling\n",
    "#if not args.use_pytorch_wavelet:\n",
    "#    dwt = DWT_2D(\"haar\")\n",
    "#    iwt = IDWT_2D(\"haar\")\n",
    "#else:\n",
    "#    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "#    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "    \n",
    "\n",
    "#load encoder and decoder\n",
    "config_path = args.AutoEncoder_config \n",
    "ckpt_path = args.AutoEncoder_ckpt \n",
    "\n",
    "if args.dataset in ['cifar10', 'stl10', 'coco']:\n",
    "\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    \n",
    "    AutoEncoder = instantiate_from_config(config['model'])\n",
    "    \n",
    "\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "    AutoEncoder.eval()\n",
    "    AutoEncoder.to(device)\n",
    "\n",
    "else:\n",
    "    AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "\"\"\"############### END DELETING ###############\"\"\"\n",
    "\n",
    "num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "exp = args.exp\n",
    "parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "exp_path = os.path.join(parent_dir, exp)\n",
    "if rank == 0:\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.makedirs(exp_path)\n",
    "        copy_source(__file__, exp_path)\n",
    "        shutil.copytree('score_sde/models', os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "coeff = Diffusion_Coefficients(args, device)\n",
    "pos_coeff = Posterior_Coefficients(args, device)\n",
    "T = get_time_schedule(args, device)\n",
    "\n",
    "if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "    checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    init_epoch = checkpoint['epoch']\n",
    "    epoch = init_epoch\n",
    "    # load G\n",
    "    netG.load_state_dict(checkpoint['netG_dict'])\n",
    "    #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "    schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "    # load D\n",
    "    netD.load_state_dict(checkpoint['netD_dict'])\n",
    "    #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "    schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "    global_step = checkpoint['global_step']\n",
    "    print(\"=> loaded checkpoint (epoch {})\"\n",
    "          .format(checkpoint['epoch']))\n",
    "else:\n",
    "    global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "'''Sigmoid learning parameter'''\n",
    "gamma = 6\n",
    "beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "alpha = 1 - 1 / (1+np.exp(-beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047ed4a8-a919-4dea-ac2a-e4ee3734afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31f6242-893d-4255-8cd6-f2127946b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = iter(data_loader)\n",
    "x, y = next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c27efc-dd2b-49e6-b27b-987e63e60eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A woman with a teddy bear salutes for the camera. ',\n",
       " 'The woman is posing for a photo with her skis. ',\n",
       " 'A bathroom is lit up with a dim yellow light.',\n",
       " \"The black cat is playing with someone's foot.\",\n",
       " 'An old fashioned tv sitting in a living room next to a piano.',\n",
       " 'an airport with a parked plane in the middle of the runway',\n",
       " 'A bus stopped at a bus stop on a city street.',\n",
       " 'A pizza that is laying down on a table.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba87163-541e-4449-8315-2164e3e3db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The black cat is playing with someone's foot.\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_data = (torch.clamp(x[3], -1, 1) + 1) / 2  # 0-1 \n",
    "\n",
    "torchvision.utils.save_image(\n",
    "    real_data, os.path.join(\"./\", 'real_data.png'))\n",
    "imgPIL = Image.open(\"./real_data.png\")  # 画像読み込み\n",
    "\n",
    "print(y[3])\n",
    "imgPIL.show()  # 画像表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba10d941-d9c8-4dc5-8370-39a8bc12292b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0182, -0.0111, -0.0123,  ...,  0.0113, -0.0514,  0.0512],\n",
      "        [ 0.0609,  0.0045,  0.0352,  ..., -0.0082,  0.0102, -0.0062],\n",
      "        [-0.0035,  0.0486, -0.0782,  ..., -0.0503,  0.0046, -0.0499],\n",
      "        ...,\n",
      "        [-0.0248,  0.0431, -0.0112,  ..., -0.0181, -0.0303, -0.0349],\n",
      "        [ 0.0022,  0.0107, -0.1118,  ..., -0.0535, -0.0497, -0.0142],\n",
      "        [-0.0090,  0.0676,  0.0399,  ...,  0.0040,  0.0728,  0.0011]],\n",
      "       device='cuda:0') <class 'torch.Tensor'>\n",
      "tensor([[ 0.0182, -0.0111, -0.0123,  ...,  0.0113, -0.0514,  0.0512],\n",
      "        [ 0.0609,  0.0045,  0.0352,  ..., -0.0082,  0.0102, -0.0062],\n",
      "        [-0.0035,  0.0486, -0.0782,  ..., -0.0503,  0.0046, -0.0499],\n",
      "        ...,\n",
      "        [-0.0248,  0.0431, -0.0112,  ..., -0.0181, -0.0303, -0.0349],\n",
      "        [ 0.0022,  0.0107, -0.1118,  ..., -0.0535, -0.0497, -0.0142],\n",
      "        [-0.0090,  0.0676,  0.0399,  ...,  0.0040,  0.0728,  0.0011]],\n",
      "       device='cuda:0') <class 'torch.Tensor'>\n",
      "None <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# train with fake\u001b[39;00m\n\u001b[1;32m     43\u001b[0m latent_z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, nz, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 44\u001b[0m x_0_predict \u001b[38;5;241m=\u001b[39m \u001b[43mnetG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m x_pos_sample \u001b[38;5;241m=\u001b[39m sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n\u001b[1;32m     47\u001b[0m output \u001b[38;5;241m=\u001b[39m netD(x_pos_sample, t, x_tp1\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/box/MyFolder/project/Latent-DDGAN/score_sde/models/ncsnpp_generator_adagn.py:344\u001b[0m, in \u001b[0;36mNCSNpp.forward\u001b[0;34m(self, x, time_cond, z)\u001b[0m\n\u001b[1;32m    342\u001b[0m m_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_resolutions:\n\u001b[0;32m--> 344\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     m_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    347\u001b[0m hs\u001b[38;5;241m.\u001b[39mappend(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/box/MyFolder/project/Latent-DDGAN/score_sde/models/layerspp.py:311\u001b[0m, in \u001b[0;36mResnetBlockBigGANpp_Adagn.forward\u001b[0;34m(self, x, temb, zemb)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, temb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zemb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 311\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGroupNorm_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzemb\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup:\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfir:\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/box/MyFolder/project/Latent-DDGAN/score_sde/models/layerspp.py:59\u001b[0m, in \u001b[0;36mAdaptiveGroupNorm.forward\u001b[0;34m(self, input, style)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, style):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(style, \u001b[38;5;28mtype\u001b[39m(style))\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle(style)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     61\u001b[0m     gamma, beta \u001b[38;5;241m=\u001b[39m style\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got NoneType)"
     ]
    }
   ],
   "source": [
    "for p in netD.parameters():\n",
    "    p.requires_grad = True\n",
    "netD.zero_grad()\n",
    "\n",
    "for p in netG.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# sample from p(x_0)\n",
    "x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "\"\"\"################# Change here: Encoder #################\"\"\"\n",
    "with torch.no_grad():\n",
    "    posterior = AutoEncoder.encode(x0)\n",
    "    real_data = posterior.sample().detach()\n",
    "#print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "\n",
    "\n",
    "#assert -1 <= real_data.min() < 0\n",
    "#assert 0 < real_data.max() <= 1\n",
    "\"\"\"################# End change: Encoder #################\"\"\"\n",
    "\n",
    "# sample t\n",
    "t = torch.randint(0, args.num_timesteps,\n",
    "                  (real_data.size(0),), device=device)\n",
    "\n",
    "x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "x_t.requires_grad = True\n",
    "\n",
    "# train with real\n",
    "D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "errD_real.backward(retain_graph=True)\n",
    "\n",
    "if args.lazy_reg is None:\n",
    "    grad_penalty_call(args, D_real, x_t)\n",
    "else:\n",
    "    if global_step % args.lazy_reg == 0:\n",
    "        grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "# train with fake\n",
    "latent_z = torch.randn(batch_size, nz, device=device)\n",
    "x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "errD_fake = F.softplus(output).mean()\n",
    "\n",
    "errD_fake.backward()\n",
    "\n",
    "errD = errD_real + errD_fake\n",
    "# Update D\n",
    "optimizerD.step()\n",
    "\n",
    "# update G\n",
    "for p in netD.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for p in netG.parameters():\n",
    "    p.requires_grad = True\n",
    "netG.zero_grad()\n",
    "\n",
    "t = torch.randint(0, args.num_timesteps,\n",
    "                  (real_data.size(0),), device=device)\n",
    "x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "latent_z = torch.randn(batch_size, nz, device=device)\n",
    "x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "errG = F.softplus(-output).mean()\n",
    "\n",
    "# reconstructior loss\n",
    "if args.sigmoid_learning and args.rec_loss:\n",
    "    ######alpha\n",
    "    rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "    errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "elif args.rec_loss and not args.sigmoid_learning:\n",
    "    rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "    errG = errG + rec_loss\n",
    "\n",
    "\n",
    "errG.backward()\n",
    "optimizerG.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34310442-04bd-4cbf-a5d4-106360bcea74",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473230c-006d-4f7d-9205-8a43e9eed543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "    #train_sampler.set_epoch(epoch)\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    for iteration, (x, y) in enumerate(data_loader):\n",
    "        if iteration % 10 == 0:\n",
    "            print(\"iteration: {}\".format(iteration))\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "        netD.zero_grad()\n",
    "\n",
    "        for p in netG.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # sample from p(x_0)\n",
    "        x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "        \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "        with torch.no_grad():\n",
    "            posterior = AutoEncoder.encode(x0)\n",
    "            real_data = posterior.sample().detach()\n",
    "        #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "        real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "        \n",
    "        \n",
    "        #assert -1 <= real_data.min() < 0\n",
    "        #assert 0 < real_data.max() <= 1\n",
    "        \"\"\"################# End change: Encoder #################\"\"\"\n",
    "\n",
    "        # sample t\n",
    "        t = torch.randint(0, args.num_timesteps,\n",
    "                          (real_data.size(0),), device=device)\n",
    "\n",
    "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "        x_t.requires_grad = True\n",
    "\n",
    "        # train with real\n",
    "        D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "        errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "        errD_real.backward(retain_graph=True)\n",
    "\n",
    "        if args.lazy_reg is None:\n",
    "            grad_penalty_call(args, D_real, x_t)\n",
    "        else:\n",
    "            if global_step % args.lazy_reg == 0:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "        # train with fake\n",
    "        latent_z = torch.randn(batch_size, nz, device=device)\n",
    "        x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "        errD_fake = F.softplus(output).mean()\n",
    "\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        # update G\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        for p in netG.parameters():\n",
    "            p.requires_grad = True\n",
    "        netG.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, args.num_timesteps,\n",
    "                          (real_data.size(0),), device=device)\n",
    "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "        latent_z = torch.randn(batch_size, nz, device=device)\n",
    "        x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "        errG = F.softplus(-output).mean()\n",
    "\n",
    "        # reconstructior loss\n",
    "        if args.sigmoid_learning and args.rec_loss:\n",
    "            ######alpha\n",
    "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "            errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "        elif args.rec_loss and not args.sigmoid_learning:\n",
    "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "            errG = errG + rec_loss\n",
    "        \n",
    "\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        global_step += 1\n",
    "        if iteration % 100 == 0:\n",
    "            if rank == 0:\n",
    "                end.record()\n",
    "                torch.cuda.synchronize()\n",
    "                elapsed_time = start.elapsed_time(end)\n",
    "                if args.sigmoid_learning:\n",
    "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
    "                        epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
    "                elif args.rec_loss:\n",
    "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
    "                        epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
    "                else:   \n",
    "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
    "                        epoch, iteration, errG.item(), errD.item()))\n",
    "                wandb.log({\"iteration:\": iteration, \"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch], \"elapsed_time\": elapsed_time / 1000})\n",
    "                start.record()\n",
    "\n",
    "    if not args.no_lr_decay:\n",
    "\n",
    "        schedulerG.step()\n",
    "        schedulerD.step()\n",
    "\n",
    "    if rank == 0:\n",
    "        ########################################\n",
    "        x_t_1 = torch.randn_like(posterior.sample())\n",
    "        fake_sample = sample_from_model(\n",
    "            pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "        \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "        fake_sample *= args.scale_factor #300\n",
    "        real_data *= args.scale_factor #300\n",
    "        with torch.no_grad():\n",
    "            fake_sample = AutoEncoder.decode(fake_sample)\n",
    "            real_data = AutoEncoder.decode(real_data)\n",
    "        \n",
    "        fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "        real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "        \n",
    "        \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "        torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "            exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "        torchvision.utils.save_image(\n",
    "            real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "\n",
    "        if args.save_content:\n",
    "            if epoch % args.save_content_every == 0:\n",
    "                print('Saving content.')\n",
    "                content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                           'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                           'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                           'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "        if epoch % args.save_ckpt_every == 0:\n",
    "            if args.use_ema:\n",
    "                optimizerG.swap_parameters_with_ema(\n",
    "                    store_params_in_ema=True)\n",
    "\n",
    "            torch.save(netG.state_dict(), os.path.join(\n",
    "                exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "            if args.use_ema:\n",
    "                optimizerG.swap_parameters_with_ema(\n",
    "                    store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0a1b8-50fd-4d39-882f-9f1020463a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015254cc-702f-4765-a067-6d1d7c8bba99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bed3ba-42ca-42c9-9c3e-702c8b137ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b418dac-04af-447b-aa8c-6a3c360a6d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7f3db-349c-40d9-8d1e-0f37fecc08b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
