{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc92f485",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Posterior_Coefficie' from 'diffusion' (/mnt/box/MyFolder/project/Latent-DDGAN/diffusion.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets_prep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_dataset\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample_from_model, sample_posterior, \\\n\u001b[1;32m     13\u001b[0m     q_sample_pairs, get_time_schedule, \\\n\u001b[1;32m     14\u001b[0m     Posterior_Coefficie\n\u001b[1;32m     15\u001b[0m nts, Diffusion_Coefficients\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#from pytorch_wavelets import DWTForward, DWTInverse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Posterior_Coefficie' from 'diffusion' (/mnt/box/MyFolder/project/Latent-DDGAN/diffusion.py)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficie\n",
    "nts, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ac15115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3847cfee-ecfc-4249-afd8-7ec70e731249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList(\n",
       "          (0-1): 2 x AttnBlock(\n",
       "            (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(4, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList(\n",
       "          (0-2): 3 x AttnBlock(\n",
       "            (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loss): LPIPSWithDiscriminator(\n",
       "    (perceptual_loss): LPIPS(\n",
       "      (scaling_layer): ScalingLayer()\n",
       "      (net): vgg16(\n",
       "        (slice1): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "        (slice2): Sequential(\n",
       "          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (8): ReLU(inplace=True)\n",
       "        )\n",
       "        (slice3): Sequential(\n",
       "          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): ReLU(inplace=True)\n",
       "          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (13): ReLU(inplace=True)\n",
       "          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (15): ReLU(inplace=True)\n",
       "        )\n",
       "        (slice4): Sequential(\n",
       "          (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (18): ReLU(inplace=True)\n",
       "          (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (20): ReLU(inplace=True)\n",
       "          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (22): ReLU(inplace=True)\n",
       "        )\n",
       "        (slice5): Sequential(\n",
       "          (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (25): ReLU(inplace=True)\n",
       "          (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (27): ReLU(inplace=True)\n",
       "          (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (29): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (lin0): NetLinLayer(\n",
       "        (model): Sequential(\n",
       "          (0): Dropout(p=0.5, inplace=False)\n",
       "          (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (lin1): NetLinLayer(\n",
       "        (model): Sequential(\n",
       "          (0): Dropout(p=0.5, inplace=False)\n",
       "          (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (lin2): NetLinLayer(\n",
       "        (model): Sequential(\n",
       "          (0): Dropout(p=0.5, inplace=False)\n",
       "          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (lin3): NetLinLayer(\n",
       "        (model): Sequential(\n",
       "          (0): Dropout(p=0.5, inplace=False)\n",
       "          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (lin4): NetLinLayer(\n",
       "        (model): Sequential(\n",
       "          (0): Dropout(p=0.5, inplace=False)\n",
       "          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (discriminator): NLayerDiscriminator(\n",
       "      (main): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "config_path = \"./autoencoder/config/cifar10_16x16x4.yaml\"\n",
    "ckpt_path = \"./autoencoder/weight/16x16x4_551.ckpt\"\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "AutoEncoder = instantiate_from_config(config['model'])\n",
    "\n",
    "\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "AutoEncoder.eval()\n",
    "AutoEncoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06dead9d-85f4-4952-8cc6-bc9f37cfc9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./autoencoder/weight/16x16x4_551.ckpt\n"
     ]
    },
    {
     "ename": "ScannerError",
     "evalue": "mapping values are not allowed here\n  in \"/mnt/box/MyFolder/project/Latent-DDGAN/autoencoder/config/COCO_config.yaml\", line 56, column 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./autoencoder/config/COCO_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./autoencoder/weight/16x16x4_551.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m AutoEncoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config_path, ckpt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_config\u001b[39m(config_path, ckpt):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mOmegaConf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     pl_sd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ckpt, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#global_step = pl_sd[\"global_step\"]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/omegaconf/omegaconf.py:190\u001b[0m, in \u001b[0;36mOmegaConf.load\u001b[0;34m(file_)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(file_), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 190\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_yaml_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(file_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     obj \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(file_, Loader\u001b[38;5;241m=\u001b[39mget_yaml_loader())\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[0;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py:127\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anchor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors[anchor] \u001b[38;5;241m=\u001b[39m node\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMappingEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m#key_event = self.peek_event()\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/parser.py:428\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_block_mapping_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeyToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    429\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(KeyToken, ValueToken, BlockEndToken):\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mchoices):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py:223\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Is it the value indicator?\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_value():\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Is it an alias?\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py:577\u001b[0m, in \u001b[0;36mScanner.fetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# We are allowed to start a complex value if and only if\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# we can start a simple key.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_simple_key:\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmapping values are not allowed here\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# If this value starts a new block mapping, we need to add\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# BLOCK-MAPPING-START.  It will be detected as an error later by\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# the parser.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n",
      "\u001b[0;31mScannerError\u001b[0m: mapping values are not allowed here\n  in \"/mnt/box/MyFolder/project/Latent-DDGAN/autoencoder/config/COCO_config.yaml\", line 56, column 17"
     ]
    }
   ],
   "source": [
    "config_path = \"./autoencoder/config/COCO_config.yaml\"\n",
    "ckpt_path = \"./autoencoder/weight/16x16x4_551.ckpt\"\n",
    "\n",
    "AutoEncoder = load_model_from_config(config_path, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2396ce6d-4138-49ed-aa9d-95b5fc3d0792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.69s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import CIFAR10, STL10\n",
    "\n",
    "from datasets_prep.coco import CustomCocoCaptions\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.transforms.CenterCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = CustomCocoCaptions(\n",
    "    name=\"train2017\",\n",
    "    root=os.path.join(\"./data/coco\", \"train2017\"),\n",
    "    annFile=os.path.join(\n",
    "    \"./data/coco\", 'annotations', 'captions_train2017.json'), \n",
    "    transform=train_transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=1,           \n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecd5c314-235e-4588-86a0-726e897e8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(\"./data/cifar-10\", train=True, transform=transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]), download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=1,           \n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42869ed2-c3cc-45db-886d-c2021032dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = iter(data_loader)\n",
    "x, y = next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8c79ad8-0f9b-4880-abc0-1e45b7926bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "scale_factor = 6.0\n",
    "x0 = x.to(device, non_blocking=True)\n",
    "with torch.no_grad():\n",
    "    posterior = AutoEncoder.encode(x0)\n",
    "    real_data = posterior.sample().detach()\n",
    "#print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "real_data = real_data / scale_factor #300.0  # [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb020d42-b504-4956-bfd7-9de347115c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTTTT\n"
     ]
    }
   ],
   "source": [
    "real_data *= scale_factor #300\n",
    "with torch.no_grad():\n",
    "    real_data = AutoEncoder.decode(real_data)\n",
    "\n",
    "real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "\n",
    "torchvision.utils.save_image(\n",
    "    real_data, os.path.join(\"./\", 'real_data.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e13d52d1-a361-409a-86a4-867f6395765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASTER_PORT=6038\n",
      "The work dir is:  /mnt/box/MyFolder/project/Latent-DDGAN\n",
      "coco_256 train 1\n",
      "==> Training LDDGAN\n",
      "starting in debug mode\n",
      "git root error: Cmd('git') failed due to: exit code(128)\n",
      "  cmdline: git rev-parse --show-toplevel\n",
      "  stderr: 'fatal: detected dubious ownership in repository at '/mnt/box/MyFolder/project/Latent-DDGAN'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/box/MyFolder/project/Latent-DDGAN'\n",
      "git root error: Cmd('git') failed due to: exit code(128)\n",
      "  cmdline: git rev-parse --show-toplevel\n",
      "  stderr: 'fatal: detected dubious ownership in repository at '/mnt/box/MyFolder/project/Latent-DDGAN'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/box/MyFolder/project/Latent-DDGAN'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkotomiya07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/box/MyFolder/project/Latent-DDGAN/wandb/run-20240723_133212-5jr69ne3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mprime-fire-71\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kotomiya07/latent-diffusion-gan\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kotomiya07/latent-diffusion-gan/runs/5jr69ne3\u001b[0m\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/box/MyFolder/project/Latent-DDGAN/train_ldgan.py\", line 540, in <module>\n",
      "    init_processes(0, size, train, args)\n",
      "  File \"/mnt/box/MyFolder/project/Latent-DDGAN/utils.py\", line 25, in init_processes\n",
      "    fn(rank, gpu, args)\n",
      "  File \"/mnt/box/MyFolder/project/Latent-DDGAN/train_ldgan.py\", line 134, in train\n",
      "    config = yaml.safe_load(file)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/__init__.py\", line 125, in safe_load\n",
      "    return load(stream, SafeLoader)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/__init__.py\", line 81, in load\n",
      "    return loader.get_single_data()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/constructor.py\", line 49, in get_single_data\n",
      "    node = self.get_single_node()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 36, in get_single_node\n",
      "    document = self.compose_document()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 55, in compose_document\n",
      "    node = self.compose_node(None, None)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/composer.py\", line 127, in compose_mapping_node\n",
      "    while not self.check_event(MappingEndEvent):\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/parser.py\", line 98, in check_event\n",
      "    self.current_event = self.state()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/parser.py\", line 428, in parse_block_mapping_key\n",
      "    if self.check_token(KeyToken):\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py\", line 116, in check_token\n",
      "    self.fetch_more_tokens()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py\", line 223, in fetch_more_tokens\n",
      "    return self.fetch_value()\n",
      "  File \"/home/kotomiya/anaconda3/envs/ddgan/lib/python3.10/site-packages/yaml/scanner.py\", line 577, in fetch_value\n",
      "    raise ScannerError(None, None,\n",
      "yaml.scanner.ScannerError: mapping values are not allowed here\n",
      "  in \"./autoencoder/config/COCO_config.yaml\", line 56, column 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mprime-fire-71\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kotomiya07/latent-diffusion-gan/runs/5jr69ne3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/kotomiya07/latent-diffusion-gan\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240723_133212-5jr69ne3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh coco_256 train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8df52-3b81-479a-927c-fb66096143b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
